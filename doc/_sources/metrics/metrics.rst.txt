Metrics Package
=================================
SoldAI utils (sutil) metrics package includes metrics to evaluate the classification results.

Classes
===============
.. py:class:: ModelROC

<<<<<<< Updated upstream
        The *ModelROC* class let's you define a evaluation metric for classification using the ROC curve to evaluate a classification model. The class calculates the predictions and plot the area under the curve.
=======
        The *ModelROC* class lets you define an evaluation metric for classification using the ROC curve to evaluate a classification model. The class calculates the predictions and plot the area under the curve.
>>>>>>> Stashed changes
        
        .. py:attribute:: model

            It's a model object previously trained that will be used to compute the predictions.

        .. py:attribute:: fpr

            False positives rate.

        .. py:attribute:: tpr

            True positives rate.

        .. py:attribute:: auc

<<<<<<< Updated upstream
            Area under the curve score
=======
            The area under the curve score.
>>>>>>> Stashed changes

        .. py:attribute:: legend

            Legend for the graph
        
        .. py:method:: __init__(model, X_test, y_test, legend = 'model')

<<<<<<< Updated upstream
            Instantiates a new ModelROC class to be evaluated using the prediction of the given X and comparing it against the y_test values. The predictipns are made invoking to the getPredictions method. Then the roc_curve method of sklearn is invoked to find the auc score
=======
            Instantiates a new ModelROC class to be evaluated using the prediction of the given X and comparing it against the y_test values. The predictions are made invoking to the getPredictions method. Then the roc_curve method of Sklearn is invoked to find the AUC score.
>>>>>>> Stashed changes
        
        .. py:method:: getPredictions(X_test)

            Return the predictions made by the self.model.predict method

        .. py:method:: plotData()

<<<<<<< Updated upstream
        	Sets the ROC curve plot data of the evaluated model using the paramters defined in the class. This class don't show the plot, only sets the values to plot

        .. py:method:: plot()

        	This method shows the ROCCurve of the plot obtained invoking to the pltData method

        .. py:method:: zoom(zoom_x, zoom_y)

        	This method recieves two tuples being the zoom ranges for the x and y axis. This method let's you zoom some part of the ROC curve plot and shows the result.
=======
        	Sets the ROC curve plot data of the evaluated model using the parameters defined in the class. This class doesn't show the plot, it only sets the values to plot.

        .. py:method:: plot()

        	This method shows the ROCCurve of the plot obtained invoking to the plotData method.

        .. py:method:: zoom(zoom_x, zoom_y)

        	This method receives two tuples being the zoom ranges for the x and y-axis. This method lets you zoom some part of the ROC curve plot and shows the result.
>>>>>>> Stashed changes
        
        Example:
        
        .. code-block:: python
        
            # -*- coding: utf-8 -*-
            import numpy as np
            from sutil.base.Dataset import Dataset
            from sutil.models.RegularizedLogisticRegression import RegularizedLogisticRegression
            from sutil.metrics.ModelROC import ModelROC

            datafile = './sutil/datasets/ex2data1.txt'
            d = Dataset.fromDataFile(datafile, ',')
            theta = np.zeros((d.n + 1, 1))
            alpha = 0.03
            l = 0
            lr = RegularizedLogisticRegression(theta, alpha, l)
            lr.trainModel(d)

            m = ModelROC(lr, d.getBiasedX(), d.y, legend = 'Example of Model ROC usage')
            m.plot()
            m.zoom((0, 0.4),(0.5, 1.0))
            
<<<<<<< Updated upstream
        This example ilustrates how to use the ModelROC class
=======
        This example illustrates how to use the ModelROC class.
>>>>>>> Stashed changes
